# coding: utf-8

"""
    Dalet Media Cortex API

    # Scope Dalet Mediator API allows you to submit long running media jobs managed by Dalet services.  Long running media jobs include: - **Media processing** such as transcoding or automatic QC. - **Automatic metadata extraction** such as automatic speech transcription or face detection.  The Dalet Mediator API is a REST API with typed schema for the payload. # Architecture Job processing is performed on the cloud via dynamic combination of microservices. Dalet Mediator adopts the [EBU MCMA] architecture.  The key objectives of this architecture are to support: - Job management and monitoring - Long running transactions - Event based communication pattern - Service registration and discovery - Horizontal scalability in an elastic manner  The architecture is implemented using the serverless approach - relying on  independent microservices accessible through well documented REST endpoints and sharing a common object model. ## Roles The following services are involved in the processing of media jobs exposed through the Dalet Media Mediator API: - **Mediator**: this is the main entry point to the architecture; this API endpoint supports: 1. Checking authentication using an API key and a token mechanism 2. Verifying quota restrictions before accepting a submitted job 3. Keeping track of usage so that job processing can be tracked and billed 4. Keeping track of jobs metadata as a job repository - **Job Processor**: once a job request is accepted by the mediator, it is assigned to a Job Processor. The Job Processor dispatches the job to an appropriate Job Worker (depending on the job profile and other criteria such as load on the system and cost of operation).  It then keeps track of the progress of the job and its status until completion and possible failures and timeout.  It reports progress to the Mediator through notifications. - **Job Worker**: The Job Worker performs the actual work on the media object, for example, AI metadata extraction (AME) or essence transcoding.  It reports progress to the Job Processor through notifications. - **Service Registry**: The Service Registry keeps track of all active services in the architecture. It is queried by the Mediator and by Processors to discover candidate services to perform jobs.  It is updated whenever a new service is launched or stopped.  The Service Registry also stores the list of all job profiles supported by one of the Job Workers deployed in the architecture. The Dalet Mediator API abstracts away from the complexity of this orchestration and provides a simple endpoint to submit long running jobs and monitor the progress of their execution.  It serves as a facade for the additional technical services for authentication, usage monitoring and service registry.  [EBU MCMA]: /https://tech.ebu.ch/groups/mcma 'EBU MCMA' ## Job Lifecycle ![Job Lifecyle Diagram](./job_lifecycle.svg 'Job Lifecycle Diagram')  ## Authentication To use the Dalet Mediator API - you must obtain an APIKey from Dalet.  This key comes in the form of two parameters: * client ID * secret  Given these two parameters, a client program must first obtain an access token (GET /auth/access-token) and then associate this token to every subsequent calls.  When the token expires, the API will return a 401 error code.  In this case, the client must request a new token and resubmit the request. 

    The version of the OpenAPI document: 2.1.0
    Contact: cortexsupport@dalet.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import ConfigDict, Field
from typing import Any, ClassVar, Dict, List, Optional
from cortex_client.models.job_output import JobOutput
from cortex_client.models.locator import Locator
from typing import Optional, Set
from typing_extensions import Self

class SpeechToTextOutput(JobOutput):
    """
    Specifies where the captions computed by the Media Cortex service are to be stored.  Different formats can be requested (EBU-TT, SRT, JSON or text). <ul> <li>jsonFormat - Location of the output file into which metadata will be stored in JSON format.  The JSON format provides a timestamp for each transcribed. </li> <li>ttmlFormat - Location of the output file into which the speech transcription will be stored as subtitles encode in EBU-TT (TTML) format.  See https://tech.ebu.ch/docs/tech/tech3350.pdf. </li> <li>srtFormat - Location of the output file into which the speech transcription will be stored as subtitles encode in SRT format. See https://en.wikipedia.org/wiki/SubRip. </li> <li>textFormat - Location of the output file into which the text of the speech transcription will be stored in simple format with no timestamps. </li> <li>draftjsFormat - Location of the output file into which the text of the speech transcription will be stored in draftjs format. </li> </ul>
    """ # noqa: E501
    json_format: Optional[Locator] = Field(default=None, alias="jsonFormat")
    ttml_format: Optional[Locator] = Field(default=None, alias="ttmlFormat")
    srt_format: Optional[Locator] = Field(default=None, alias="srtFormat")
    text_format: Optional[Locator] = Field(default=None, alias="textFormat")
    draftjs_format: Optional[Locator] = Field(default=None, alias="draftjsFormat")
    __properties: ClassVar[List[str]] = ["jobOutputType", "jsonFormat", "ttmlFormat", "srtFormat", "textFormat", "draftjsFormat"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of SpeechToTextOutput from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of json_format
        if self.json_format:
            _dict['jsonFormat'] = self.json_format.to_dict()
        # override the default output from pydantic by calling `to_dict()` of ttml_format
        if self.ttml_format:
            _dict['ttmlFormat'] = self.ttml_format.to_dict()
        # override the default output from pydantic by calling `to_dict()` of srt_format
        if self.srt_format:
            _dict['srtFormat'] = self.srt_format.to_dict()
        # override the default output from pydantic by calling `to_dict()` of text_format
        if self.text_format:
            _dict['textFormat'] = self.text_format.to_dict()
        # override the default output from pydantic by calling `to_dict()` of draftjs_format
        if self.draftjs_format:
            _dict['draftjsFormat'] = self.draftjs_format.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of SpeechToTextOutput from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "jobOutputType": obj.get("jobOutputType"),
            "jsonFormat": Locator.from_dict(obj["jsonFormat"]) if obj.get("jsonFormat") is not None else None,
            "ttmlFormat": Locator.from_dict(obj["ttmlFormat"]) if obj.get("ttmlFormat") is not None else None,
            "srtFormat": Locator.from_dict(obj["srtFormat"]) if obj.get("srtFormat") is not None else None,
            "textFormat": Locator.from_dict(obj["textFormat"]) if obj.get("textFormat") is not None else None,
            "draftjsFormat": Locator.from_dict(obj["draftjsFormat"]) if obj.get("draftjsFormat") is not None else None
        })
        return _obj


